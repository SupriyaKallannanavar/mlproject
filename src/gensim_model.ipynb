{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c3729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7b07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d204666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message\\t</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAS KERNEL INFO instruction cache parity error...</td>\n",
       "      <td>cache.error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAS KERNEL INFO instruction cache parity error...</td>\n",
       "      <td>cache.error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAS KERNEL INFO instruction cache parity error...</td>\n",
       "      <td>cache.error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAS KERNEL INFO 63543 double-hummer alignment ...</td>\n",
       "      <td>alignment.exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAS KERNEL FATAL data storage interrupt\\t</td>\n",
       "      <td>data.error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           message\\t             category\n",
       "0  RAS KERNEL INFO instruction cache parity error...          cache.error\n",
       "1  RAS KERNEL INFO instruction cache parity error...          cache.error\n",
       "2  RAS KERNEL INFO instruction cache parity error...          cache.error\n",
       "3  RAS KERNEL INFO 63543 double-hummer alignment ...  alignment.exception\n",
       "4          RAS KERNEL FATAL data storage interrupt\\t           data.error"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11c3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_lines=list()\n",
    "lines = df['message\\t'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845da044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    tokens=word_tokenize(line)\n",
    "    #lowecase\n",
    "    tokens=[w.lower() for w in tokens]\n",
    "    #remove punctuations\n",
    "    table=str.maketrans('', '', string.punctuation)\n",
    "    stripped= [w.translate(table) for w in tokens]\n",
    "    #removing remaining tokens that are not albhabets\n",
    "    words= [word for word in stripped if word.isalpha]\n",
    "    #filter stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    message_lines.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537cf350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(message_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e375ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 40\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "EMBEDDING_DIM=100\n",
    "#Train word2vec model\n",
    "model = gensim.models.Word2Vec(sentences=message_lines, vector_size=EMBEDDING_DIM, window=5, workers=4, min_count=1)\n",
    "#vocab size\n",
    "words=list(model.wv.key_to_index)\n",
    "print(\"Vocabulary size: %d\" % len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2646cd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('message', 0.25165846943855286),\n",
       " ('0', 0.20777487754821777),\n",
       " ('info', 0.19602042436599731),\n",
       " ('purpose', 0.19170905649662018),\n",
       " ('spent', 0.18937692046165466),\n",
       " ('fatal', 0.18103456497192383),\n",
       " ('microseconds', 0.16546376049518585),\n",
       " ('exception', 0.12770980596542358),\n",
       " ('ciostream', 0.12643198668956757),\n",
       " ('parity', 0.11647110432386398)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar words(semantic info)\n",
    "model.wv.most_similar('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4ca84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "filename = 'message_embedding_word2vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d69536bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index={}\n",
    "f = open(os.path.join('', 'message_embedding_word2vec.txt'), encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c814b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 unique tokens\n",
      "Shape of message tensor: (149, 11)\n",
      "Shape of category tensor: (149,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#vectorise the text samples into a 2D tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(message_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(message_lines)\n",
    "\n",
    "#max_length=max(len(s.split() for s in message_lines))\n",
    "\n",
    "#pad sequences\n",
    "word_index = tokenizer_obj.word_index\n",
    "print(\"Found %s unique tokens\" %len(word_index))\n",
    "\n",
    "message_pad = pad_sequences(sequences, padding='pre')\n",
    "category=df['category'].values\n",
    "print('Shape of message tensor:', message_pad.shape)\n",
    "print('Shape of category tensor:', category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc51c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "category=lb.fit_transform(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb892457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 3, 6, 3, 1, 3, 3, 0, 0, 0, 3, 3, 1, 3, 0, 1, 6, 6, 6,\n",
       "       1, 6, 1, 6, 0, 0, 3, 3, 1, 3, 3, 0, 0, 1, 3, 3, 3, 0, 0, 0, 3, 3,\n",
       "       5, 3, 1, 1, 1, 1, 1, 5, 6, 4, 6, 4, 6, 5, 6, 5, 5, 6, 6, 6, 5, 5,\n",
       "       6, 5, 5, 5, 6, 4, 5, 5, 6, 6, 5, 5, 5, 5, 6, 8, 8, 8, 8, 8, 4, 8,\n",
       "       4, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 4, 8, 8, 8, 8, 8, 8,\n",
       "       8, 7, 2, 2, 2, 2, 2, 7, 7, 7, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 2, 2,\n",
       "       7, 7, 7, 7, 2, 2, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35a1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b83fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f523221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5362b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         4100      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 40)                17040     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,140\n",
      "Trainable params: 17,040\n",
      "Non-trainable params: 4,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "#define model\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM,\n",
    "                          # embeddings_initializer=Constant(embedding_matrix),\n",
    "                           trainable=False)\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=40,dropout=0.2))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132cf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a121edc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad tensor: (120, 11)\n",
      "Shape of y_train tensor: (120,)\n",
      "Shape of X_test_pad tensor: (29, 11)\n",
      "Shape of y_test tensor: (29,)\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SPLIT =0.2\n",
    "\n",
    "indices = np.arange(message_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "message_pad= message_pad[indices]\n",
    "category=category[indices]\n",
    "num_validation_samples=int(VALIDATION_SPLIT * message_pad.shape[0])\n",
    "\n",
    "X_train_pad = message_pad[: -num_validation_samples]\n",
    "y_train = category[:-num_validation_samples]\n",
    "X_test_pad = message_pad[-num_validation_samples:]\n",
    "y_test = category[-num_validation_samples:]\n",
    "\n",
    "print('Shape of X_train_pad tensor:', X_train_pad.shape)\n",
    "print('Shape of y_train tensor:', y_train.shape)\n",
    "\n",
    "print('Shape of X_test_pad tensor:', X_test_pad.shape)\n",
    "print('Shape of y_test tensor:', y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7afdda41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10\n",
      "7/7 - 2s - loss: 7.5546 - accuracy: 0.1833 - val_loss: 5.4267 - val_accuracy: 0.1379 - 2s/epoch - 322ms/step\n",
      "Epoch 2/10\n",
      "7/7 - 0s - loss: 4.7346 - accuracy: 0.2667 - val_loss: 3.5947 - val_accuracy: 0.1379 - 89ms/epoch - 13ms/step\n",
      "Epoch 3/10\n",
      "7/7 - 0s - loss: 3.0995 - accuracy: 0.4000 - val_loss: 3.2632 - val_accuracy: 0.3448 - 85ms/epoch - 12ms/step\n",
      "Epoch 4/10\n",
      "7/7 - 0s - loss: 2.7931 - accuracy: 0.4583 - val_loss: 3.0729 - val_accuracy: 0.4483 - 77ms/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "7/7 - 0s - loss: 2.5891 - accuracy: 0.5500 - val_loss: 2.9032 - val_accuracy: 0.5517 - 98ms/epoch - 14ms/step\n",
      "Epoch 6/10\n",
      "7/7 - 0s - loss: 2.3764 - accuracy: 0.6750 - val_loss: 2.6916 - val_accuracy: 0.5517 - 85ms/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "7/7 - 0s - loss: 2.1617 - accuracy: 0.7583 - val_loss: 2.4385 - val_accuracy: 0.5862 - 81ms/epoch - 12ms/step\n",
      "Epoch 8/10\n",
      "7/7 - 0s - loss: 1.8965 - accuracy: 0.7833 - val_loss: 2.1032 - val_accuracy: 0.7586 - 87ms/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "7/7 - 0s - loss: 1.4798 - accuracy: 0.8500 - val_loss: 0.8044 - val_accuracy: 0.8621 - 84ms/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "7/7 - 0s - loss: 1.0408 - accuracy: 0.8500 - val_loss: 0.6368 - val_accuracy: 0.8621 - 91ms/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea6968f880>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "\n",
    "\n",
    "model.fit(X_train_pad, y_train,batch_size=18, epochs =10, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de9aa640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.6368 - accuracy: 0.8621 - 34ms/epoch - 34ms/step\n",
      "Test accuracy: 0.8620689511299133\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test_pad, y_test,\n",
    "                        verbose=2)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d8f37dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 365ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction= model.predict(X_test_pad)\n",
    "predictions = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5fa100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 4]\n",
      " [0 0 0 0 5 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f663c74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e826860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         4\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         2\n",
      "          28       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86        29\n",
      "   macro avg       0.80      0.80      0.80        29\n",
      "weighted avg       0.86      0.86      0.86        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0018d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2aebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c9407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
